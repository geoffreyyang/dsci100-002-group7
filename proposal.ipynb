{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal - Will it Rain Tomorrow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern weather forecasting requires millions of data points, complex mathematical models, and powerful supercomputers<sup>1</sup>. But what if the goal was not to predict \"the weather\", but rather to predict *whether or not it will rain tomorrow*? Can this less ambitious question be answered accurately using simpler variables, fewer data points, and less computational horsepower?  \n",
    "\n",
    "Our goal is to answer the question, ***which broad weather variable, when measured today, is most predictive of rain tomorrow?*** We will use the **\"Rain in Australia\"** dataset, publicly avaialable on Kaggle<sup>2</sup>. It contains more than 140,000 weather observations gathered from locations across Australia over a span of 10 years. The target variable is `RainTomorrow`, a Boolean: `Yes` if it rained the day after, and `No` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({\n",
    "library(tidyverse) \n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(forcats) \n",
    "library(grid)\n",
    "library(gridExtra)\n",
    "})\n",
    "\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather <- read_csv(\"https://github.com/geoffreyyang/dsci100-002-group7/raw/main/data/weatherAUS.csv\")\n",
    "glimpse(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems `readr` parsed the `Evaporation` and `Sunshine` columns as logical vectors when they are actually doubles, so we coerce them to numeric using `as.numeric`. We convert the class labels `RainToday` and `RainTomorrow` into factors.  \n",
    "\n",
    "We check the number of NAs using `colSums`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_not_tidy <- weather %>%\n",
    "    # Fixing initial parsing error\n",
    "    mutate(Evaporation = as.numeric(Evaporation), Sunshine = as.numeric(Sunshine)) %>%\n",
    "    # Converting class labels to factors\n",
    "    mutate(RainToday = as_factor(RainToday), RainTomorrow = as_factor(RainTomorrow))\n",
    "\n",
    "# How many NAs are there?\n",
    "colSums(is.na(weather_not_tidy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the `Evaporation` and `Sunshine` columns since more than 95% are NAs. We keep all the other numerical variables, even `Cloud9am` and `Cloud9pm`, and instead dropp the *rows* that have NA values for them. Although we will lose data, we will still end up with more than enough for training and testing.\n",
    "\n",
    "We split our data 75:25 into training and testing sets, the ratio used in the textbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidy <- weather_not_tidy %>%\n",
    "    # Drop Evaporation and Sunshine\n",
    "    select(-Evaporation, -Sunshine) %>%\n",
    "    # Get rid of all rows with NAs in variables we might use\n",
    "    drop_na(MinTemp, MaxTemp, Rainfall, WindGustSpeed, WindSpeed9am:RainTomorrow)\n",
    "    \n",
    "set.seed(1)\n",
    "weather_split <- initial_split(weather_tidy, prop = 0.75, strata = RainTomorrow)\n",
    "weather_train <- training(weather_split)\n",
    "weather_test <- testing(weather_split)\n",
    "\n",
    "# Are our class variables factors?\n",
    "class(weather_train$RainToday)\n",
    "class(weather_train$RainTomorrow)\n",
    "\n",
    "# Do we have enough training and testing data, in the right proportions?\n",
    "nrow(weather_train)\n",
    "nrow(weather_test)\n",
    "\n",
    "# How bad is the class imbalance?\n",
    "summary(weather_train$RainTomorrow)\n",
    "\n",
    "# How many NAs are there?\n",
    "colSums(is.na(weather_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RainTomorrow` has been successfully turned into a factor and our data is tidy. There is some class imbalance (3.3:1 ratio) - we are not sure if this will be problematic for KNN analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using only training data, summarize the data in at least one table**\n",
    "- **An example of a useful table could be one that reports the number of observations in each class, the means of the predictor variables you plan to use in your analysis and how many rows have missing data.**\n",
    "- *Maybe we could make a table where each row is a different predictor (e.g. `Humidity9am`), and there are four columns: `Predictor`, `Mean(no rain tomorrow)`, `Mean(rain tomorrow)`, and `Difference`: the rows with the biggest `Difference` would be the most useful predictors*\n",
    "- *Or we could stick with the simple table they suggest*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 10 graphs representing each of our proposed predictor variables and the classifier variable. The predictor variables are further outlined in the Methods section; however, here is a summary of the variables we will be using:\n",
    "1. **Temperature** (`Temp9am` and `Temp3pm`)\n",
    "2. **Humidity** (`Humidity9am` and `Humidity3pm`)\n",
    "3. **Pressure** (`Pressure9am` and `Pressure3pm`)\n",
    "4. **Windiness** (`WindSpeed9am`, `WindSpeed3pm`)\n",
    "5. **Cloudiness** (`Cloud9am` and `Cloud3pm`)  \n",
    "\n",
    "Each graph is coloured based on the classifier variable: Rain Tomorrow. In each graph, the red line represents data for rows in which it did not rain tomorrow. Subsequently, the blue line represents data for rows in which it did rain tomorrow.\n",
    "\n",
    "We chose to present this data as frequency polygons. This type of graph provides a visualization of the trends in a histogram, and presents the data for each boolean value of the classifier variable seperately. This makes it easy to visualise how each predictor variable relates to wether or not it will rain tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set plot width and height (represents the size of entire plot grid)\n",
    "options(repr.plot.height = 20, repr.plot.width = 20)\n",
    "\n",
    "# Storing the names of each column to plot in a vector - to be provided as x in the aes of ggplot\n",
    "loop.names = names(weather_train)[10:19]\n",
    "\n",
    "# Storing the names of each x-labes in a vector - to be provided as x in the labs of ggplot\n",
    "loop.lab = c(\"Wind Speed averaged over 10 minutes prior to 9am (km/hr)\", \"Windspeed averaged over 10 minutes prior to 3pm (km/hr)\", \n",
    "               \"Humidity at 9am (percent)\", \"Humidity at 3pm (percent)\", \n",
    "               \"Atmospheric Pressure at 9am (hpa) reduced to mean sea level\", \"Atmospheric Pressure at 3pm (hpa) reduced to mean sea level\",\n",
    "              \"Fraction of sky covered by clouds at 9am (oktas)\", \"Fraction of sky covered by clouds at 3pm (oktas)\",\n",
    "              \"Temperature at 9am (Celsius)\", \"Temperature at 3pm (Celsius)\")\n",
    "\n",
    "\n",
    "# initialize p (plot list) as an empty list with length 10\n",
    "p <- vector('list', 10)\n",
    "\n",
    "# Loops runs 10 times (once for each plot). Takes the nth item from loop.names and loop.title, prints a ggplot with each variable in the corresponding locations\n",
    "for(i in 1:10) {\n",
    "    \n",
    "    #at each loop iteration, get the ith number in loop.names and loop.lab\n",
    "    x_name <- unlist(weather_train[,nth(loop.names, i)])\n",
    "    lab_name <- nth(loop.lab, i)\n",
    "    \n",
    "    # at each iteration, create a plot with x_name and lab_name. using aes_string to prevent lazy loding when p[[i]] is called later\n",
    "    p[[i]] <- ggplot(weather_train, aes_string(x=x_name, colour = \"RainTomorrow\")) +\n",
    "                            geom_freqpoly(binwidth=2, size = 1.5) +\n",
    "                            theme(text = element_text(size = 15)) +\n",
    "                            labs(color = \"Rain Tomorrow?\", \n",
    "                            x = lab_name, y = \"Frequency\")\n",
    "    }\n",
    "\n",
    "\n",
    "#arrange plots in a grid\n",
    "grid.arrange(p[[1]], p[[2]], p[[3]], p[[4]], p[[5]], p[[6]], p[[7]], p[[8]], p[[9]], p[[10]], nrow=5, top = textGrob(\"Plots of the predictor variables and Rain Tomorrow\", gp=gpar(fontsize=28,font=8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to build five separate KNN classifiers capturing 5 broad weather variables:\n",
    "1. **Temperature** (`Temp9am` and `Temp3pm`)\n",
    "2. **Humidity** (`Humidity9am` and `Humidity3pm`)\n",
    "3. **Pressure** (`Pressure9am` and `Pressure3pm`)\n",
    "4. **Windiness** (`WindSpeed9am`, `WindSpeed3pm`)\n",
    "5. **Cloudiness** (`Cloud9am` and `Cloud3pm`)  \n",
    "\n",
    "For each of these five broad variables, we will build and tune a classifier using 5-fold cross-validation. We will then evaluate which classifier (which variable) is the most predictive for `RainTomorrow`. Next, we will build a classifier using *all the numeric variables in the dataset* as predictors. This will let us compare the effectiveness of our chosen \"heuristic\" variable with the \"best accuracy\" we can achieve from our data. We may use KNN again, but if it becomes slow, we might use a more efficient algorithm. Finally, we will compare the accuracy of these classifiers to the \"naive approach\" of predicting \"it will rain tomorrow if it rained today\", and vice-versa, to see if our models actually contribute value.\n",
    "\n",
    "**Possible visualizations include:**\n",
    "- K versus accuracy plot\n",
    "- Bar graph: accuracy of 7 classifiers\n",
    "- Confusion matrix: best single classifier + complete classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected outcomes and significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect our best single variable classifier will be able to predict `RainTomorrow` accurately. The classifier incorporating all predictors will perform better, but not *much* better despite the additional computational expense. Both will perform better than the naive approach.\n",
    "\n",
    "Finding variables highly associated with rain could be useful when we are unable to check the weather forecast on our phones. The most significant outcome will be predicting rain accurately despite using *significantly* less computing power and data than contemporary weather models.  \n",
    "\n",
    "This would raise several questions for future exploration. If we were accurate despite limited computing power, are there more computationally efficient methods available to meteorologists if they *only* had to forecast rain? If rain can be predicted with just a few variables, how many of the sensors installed in weather stations are truly necessary %>% ? Finally, how effective would our approach be at regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.nationalgeographic.com/environment/article/weather-forecasting  \n",
    "[2] https://www.kaggle.com/jsphyg/weather-dataset-rattle-package?select=weatherAUS.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
